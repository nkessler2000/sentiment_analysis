{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "\n",
    "# import modules and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os \n",
    "from scipy import stats\n",
    "\n",
    "my_dir = os.path.realpath('.')\n",
    "db_file = os.path.join(my_dir, '../../gr_sentiment_analysis/data/books.db')\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "review_stats = pd.read_sql_query('SELECT * FROM review_stats',con=conn)\n",
    "\n",
    "# Clean up the data a bit. Remove reviews with a score of 0 since they won't be part of the prediction model \n",
    "\n",
    "review_stats = review_stats[review_stats['rating'] != 0]\n",
    "\n",
    "# Review ID is not needed for this analysis so should be dropped\n",
    "if review_stats.columns.contains('review_id'):\n",
    "    review_stats.drop('review_id', axis=1, inplace=True)\n",
    "\n",
    "# remove any reviews with a total AFINN or Bing count of 0, since this means there are no matching\n",
    "# words in either lexicon and these reviews cannot be used in this analysis\n",
    "review_stats = review_stats[(review_stats.total_afinn_count != 0) & (review_stats.total_bing_count != 0)\n",
    "                           & (review_stats.total_mpqa_count != 0) & (review_stats.total_inq_count != 0)]\n",
    "# this leaves 918438 total reviews\n",
    "\n",
    "# remove outliers where the Z-score of the pos or neg word counts is < 3\n",
    "review_stats = review_stats[(\n",
    "    np.abs(stats.zscore(review_stats[['pos_afinn_count', 'neg_afinn_count', \n",
    "                                      'pos_bing_count', 'neg_bing_count',\n",
    "                                      'pos_mpqa_count', 'neg_mpqa_count',\n",
    "                                      'pos_inq_count', 'neg_inq_count']])) < 3\n",
    ").all(axis=1)]\n",
    "\n",
    "# with all outliers removed (having a count +/- 3 SDs), 889807 rows remain. \n",
    "\n",
    "# Rating is our target variable, the other columns are features. \n",
    "y = review_stats['rating'].values\n",
    "X = review_stats.drop('rating', axis=1).values\n",
    "\n",
    "# Create a training and testing set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_forest = {'n_estimators': stats.randint(1,30), \n",
    "             'max_features': ['auto', 'log2', None],\n",
    "             'criterion': ['gini', 'entropy'],\n",
    "             'min_samples_split': [2, 5, 10], \n",
    "             'max_depth': [3, 5, 10, None],\n",
    "             'bootstrap': [True, False]}\n",
    "\n",
    "rf_cv = RandomizedSearchCV(rf, param_forest, cv=5, n_iter=10, n_jobs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = rf_cv.predict(X_test)\n",
    "\n",
    "#stats \n",
    "from sklearn.metrics import classification_report\n",
    "print(rf_cv.best_params_)\n",
    "print(rf_cv.best_score_)\n",
    "\n",
    "# still getting a score around 0.37, around the same as the other classifiers. Not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, max_features='auto', min_samples_split=10,\n",
    "                            n_estimators=18, criterion='entropy', bootstrap=True)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.01      0.01      6602\n",
      "          2       0.33      0.00      0.00     15786\n",
      "          3       0.31      0.03      0.05     39794\n",
      "          4       0.35      0.79      0.49     61421\n",
      "          5       0.48      0.31      0.38     51986\n",
      "\n",
      "avg / total       0.38      0.38      0.29    175589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_y_pred = rf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-984f2c2556a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# let's try this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m col_importance = pd.DataFrame({'col':review_stats.drop('rating', axis=1).columns,\n\u001b[1;32m----> 3\u001b[1;33m                                'importance':rf.feature_importances_})\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcol_importance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    328\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    329\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   6161\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6163\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6164\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6165\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   6209\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6211\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arrays must all be same length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6213\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# let's try this\n",
    "col_importance = pd.DataFrame({'col':review_stats.drop('rating', axis=1).columns,\n",
    "                               'importance':rf.feature_importances_})\n",
    "\n",
    "col_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# from this, we see that exclamation count has an outsized influence. Is it really that important in predicting the review\n",
    "# score? This is supposed to be word sentiment analysis\n",
    "# bing mean, pos_bing_ratio, words_ratio, \n",
    "\n",
    "# unimportant columns appear to be neg_afinn_ratio, pos_afinn_ratio, neg_afinn_count, pos_afinn_count, cap_words_count, \n",
    "# total_bing_count, pos_bing_count, pos_afinn_count, bing_median\n",
    "\n",
    "# these are the ratios of positive words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.21      0.02      0.04      6664\n",
      "          2       0.20      0.00      0.01     15953\n",
      "          3       0.22      0.07      0.11     40160\n",
      "          4       0.35      0.65      0.46     62340\n",
      "          5       0.42      0.39      0.40     52845\n",
      "\n",
      "avg / total       0.32      0.36      0.31    177962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If I scale the values, do I get the same result? \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# pipeline = Pipeline(steps)\n",
    "scaler = StandardScaler()\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "X_train_minmax = minmax.fit_transform(X_train)\n",
    "X_test_minmax = minmax.fit_transform(X_test)\n",
    "\n",
    "rf.fit(X_train_minmax, y_train)\n",
    "rf_y_pred = rf.predict(X_test_minmax)\n",
    "\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# no, it is in fact even worse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.24      0.02      0.04      6664\n",
      "          2       0.15      0.00      0.00     15953\n",
      "          3       0.24      0.02      0.03     40160\n",
      "          4       0.35      0.81      0.49     62340\n",
      "          5       0.43      0.26      0.32     52845\n",
      "\n",
      "avg / total       0.33      0.36      0.28    177962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_dropped = review_stats.drop(['rating', 'bing_median', 'pos_afinn_count', 'neg_afinn_count', 'pos_bing_count', 'neg_bing_count', \n",
    "                              'exclamation_count', 'cap_words_count', 'total_afinn_count', 'total_bing_count'], axis=1).values\n",
    "\n",
    "\n",
    "X_train_dropped, X_test_dropped, y_train, y_test = train_test_split(\n",
    "    X_dropped, y, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_dropped = scaler.fit_transform(X_train_dropped)\n",
    "X_test_dropped = scaler.fit_transform(X_test_dropped)\n",
    "\n",
    "rf.fit(X_train_dropped, y_train)\n",
    "rf_y_pred = rf.predict(X_test_dropped)\n",
    "\n",
    "print(classification_report(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bing_mean</td>\n",
       "      <td>0.259597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afinn_median</td>\n",
       "      <td>0.130836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afinn_sum</td>\n",
       "      <td>0.102665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos_bing_ratio</td>\n",
       "      <td>0.099443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bing_words_ratio</td>\n",
       "      <td>0.090472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>afinn_words_ratio</td>\n",
       "      <td>0.057237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>all_caps_density</td>\n",
       "      <td>0.046450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neg_afinn_density</td>\n",
       "      <td>0.037892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afinn_mean</td>\n",
       "      <td>0.031930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word_count</td>\n",
       "      <td>0.027284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neg_bing_density</td>\n",
       "      <td>0.024864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pos_afinn_density</td>\n",
       "      <td>0.019658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg_bing_ratio</td>\n",
       "      <td>0.018730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg_afinn_ratio</td>\n",
       "      <td>0.014586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pos_bing_density</td>\n",
       "      <td>0.013767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos_afinn_ratio</td>\n",
       "      <td>0.013203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bing_sum</td>\n",
       "      <td>0.011388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  col  importance\n",
       "1           bing_mean    0.259597\n",
       "2        afinn_median    0.130836\n",
       "3           afinn_sum    0.102665\n",
       "7      pos_bing_ratio    0.099443\n",
       "15   bing_words_ratio    0.090472\n",
       "14  afinn_words_ratio    0.057237\n",
       "16   all_caps_density    0.046450\n",
       "12  neg_afinn_density    0.037892\n",
       "0          afinn_mean    0.031930\n",
       "5          word_count    0.027284\n",
       "13   neg_bing_density    0.024864\n",
       "10  pos_afinn_density    0.019658\n",
       "9      neg_bing_ratio    0.018730\n",
       "8     neg_afinn_ratio    0.014586\n",
       "11   pos_bing_density    0.013767\n",
       "6     pos_afinn_ratio    0.013203\n",
       "4            bing_sum    0.011388"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_dropped = review_stats.drop(['rating', 'bing_median', 'pos_afinn_count', 'neg_afinn_count', 'pos_bing_count', 'neg_bing_count', \n",
    "                              'exclamation_count', 'cap_words_count', 'total_afinn_count', 'total_bing_count'], axis=1)\n",
    "\n",
    "\n",
    "col_importance_dropped = pd.DataFrame({'col':rs_dropped.columns,\n",
    "                               'importance':rf.feature_importances_})\n",
    "\n",
    "col_importance_dropped.sort_values('importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.08      0.00      0.00      6664\n",
      "          2       0.12      0.00      0.00     15953\n",
      "          3       0.26      0.01      0.03     40160\n",
      "          4       0.35      0.83      0.49     62340\n",
      "          5       0.41      0.22      0.28     52845\n",
      "\n",
      "avg / total       0.32      0.36      0.26    177962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Well, no luck there either. It could be that the data just doesn't work for this problem. The values are too spread out. \n",
    "# What if I just use afinn_sum, bing_sum, afinn_mean, and bing_mean\n",
    "\n",
    "X_reduced = review_stats[['afinn_sum', 'bing_sum', 'afinn_mean', 'bing_mean']].values\n",
    "\n",
    "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=1)\n",
    "\n",
    "rf.fit(X_train_reduced, y_train)\n",
    "rf_y_pred = rf.predict(X_test_reduced)\n",
    "\n",
    "print(classification_report(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bing_mean</td>\n",
       "      <td>0.523763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afinn_mean</td>\n",
       "      <td>0.212837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afinn_sum</td>\n",
       "      <td>0.212440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bing_sum</td>\n",
       "      <td>0.050959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          col  importance\n",
       "3   bing_mean    0.523763\n",
       "2  afinn_mean    0.212837\n",
       "0   afinn_sum    0.212440\n",
       "1    bing_sum    0.050959"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_importance_reduced = pd.DataFrame({'col':['afinn_sum', 'bing_sum', 'afinn_mean', 'bing_mean'],\n",
    "                               'importance':rf.feature_importances_})\n",
    "\n",
    "col_importance_reduced.sort_values('importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.16      0.25     62182\n",
      "          1       0.67      0.93      0.78    113407\n",
      "\n",
      "avg / total       0.63      0.66      0.59    175589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_stats['pos_review'] = 0\n",
    "review_stats.loc[review_stats['rating'] >= 4,'pos_review'] = 1\n",
    "\n",
    "y_pos = review_stats['pos_review'].values\n",
    "X_pos = review_stats.drop(['rating', 'pos_review'], axis=1).values\n",
    "\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(\n",
    "    X_pos, y_pos, test_size=0.2, random_state=1)\n",
    "\n",
    "rf.fit(X_train_pos, y_train_pos)\n",
    "rf.score(X_test_pos, y_test_pos)\n",
    "rf_y_new_pred = rf.predict(X_test_pos)\n",
    "print(classification_report(y_test_pos, rf_y_new_pred))\n",
    "\n",
    "# Even with the simplified classification that's still not very good. Is there something wrong with the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('minmax', MinMaxScaler(copy=True, feature_range=(0, 1))), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the MinMaxScaler to see if we'd get a different result\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "steps = [('minmax', MinMaxScaler()),\n",
    "         ('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-02a2d204d972>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "rf_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.316410244884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.10      0.06      0.08      6664\n",
      "          2       0.13      0.09      0.11     15953\n",
      "          3       0.25      0.26      0.25     40160\n",
      "          4       0.36      0.42      0.39     62340\n",
      "          5       0.36      0.34      0.35     52845\n",
      "\n",
      "avg / total       0.31      0.32      0.31    177962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>afinn_mean</th>\n",
       "      <th>bing_mean</th>\n",
       "      <th>afinn_median</th>\n",
       "      <th>bing_median</th>\n",
       "      <th>afinn_sum</th>\n",
       "      <th>bing_sum</th>\n",
       "      <th>word_count</th>\n",
       "      <th>pos_afinn_count</th>\n",
       "      <th>neg_afinn_count</th>\n",
       "      <th>...</th>\n",
       "      <th>neg_bing_ratio</th>\n",
       "      <th>pos_afinn_density</th>\n",
       "      <th>pos_bing_density</th>\n",
       "      <th>neg_afinn_density</th>\n",
       "      <th>neg_bing_density</th>\n",
       "      <th>afinn_words_ratio</th>\n",
       "      <th>bing_words_ratio</th>\n",
       "      <th>cap_words_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>all_caps_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31977</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427067</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.075758</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160033</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751317</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>-0.063830</td>\n",
       "      <td>-0.021277</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43786</th>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270377</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>189</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.058201</td>\n",
       "      <td>-0.021164</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532591</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.115385</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>383</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.013055</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>-0.075718</td>\n",
       "      <td>-0.015666</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>85</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>-0.117647</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496017</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>318</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>0.069182</td>\n",
       "      <td>0.088050</td>\n",
       "      <td>-0.094340</td>\n",
       "      <td>-0.056604</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431512</th>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>282</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169853</th>\n",
       "      <td>1</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>-0.012821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907080</th>\n",
       "      <td>1</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324050</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568210</th>\n",
       "      <td>1</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>258</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207934</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>303</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>-0.039604</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902517</th>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>343</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361398</th>\n",
       "      <td>1</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>272</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>-0.022059</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883237</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>177</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.079096</td>\n",
       "      <td>0.079096</td>\n",
       "      <td>-0.101695</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218606</th>\n",
       "      <td>1</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>252</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.043651</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529759</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>-0.073171</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947297</th>\n",
       "      <td>1</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233868</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>285</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506925</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884102</th>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>350</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587768</th>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>342</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989805</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>387</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>-0.031008</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304347</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803024</th>\n",
       "      <td>1</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766485</th>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>-0.056338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911210</th>\n",
       "      <td>1</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.043046</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248905</th>\n",
       "      <td>5</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72122</th>\n",
       "      <td>5</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549133</th>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791652</th>\n",
       "      <td>5</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>194</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.067010</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.087629</td>\n",
       "      <td>0.015464</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485417</th>\n",
       "      <td>5</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>304</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.095395</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.148026</td>\n",
       "      <td>0.029605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455091</th>\n",
       "      <td>5</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>-0.037037</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>298</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.043624</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>-0.003356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268031</th>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>-0.023256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530998</th>\n",
       "      <td>5</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346750</th>\n",
       "      <td>5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>366</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92748</th>\n",
       "      <td>5</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63174</th>\n",
       "      <td>5</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809832</th>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80209</th>\n",
       "      <td>5</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590541</th>\n",
       "      <td>5</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>218</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.096330</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930879</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536222</th>\n",
       "      <td>5</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527922</th>\n",
       "      <td>5</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>228</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209239</th>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>-0.010638</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470908</th>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326468</th>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653514</th>\n",
       "      <td>5</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347435</th>\n",
       "      <td>5</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>269</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.055762</td>\n",
       "      <td>0.070632</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>0.063197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508818</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636572</th>\n",
       "      <td>5</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12184</th>\n",
       "      <td>5</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>192</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727546</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>-0.050209</td>\n",
       "      <td>-0.020921</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773250</th>\n",
       "      <td>5</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>490</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.038776</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.059184</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281119</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>-0.037736</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825828</th>\n",
       "      <td>5</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>234</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.098291</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.021368</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797247</th>\n",
       "      <td>5</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  afinn_mean  bing_mean  afinn_median  bing_median  afinn_sum  \\\n",
       "31977        1    4.000000   0.000000           4.0          0.0        4.0   \n",
       "427067       1   -1.500000  -1.000000          -2.0         -1.0       -6.0   \n",
       "160033       1    2.000000   1.000000           2.0          1.0        8.0   \n",
       "751317       1   -0.750000  -0.333333          -1.0         -1.0       -3.0   \n",
       "43786        1    0.166667   0.600000           0.5          1.0        1.0   \n",
       "270377       1   -0.307692  -0.294118           1.0         -1.0       -4.0   \n",
       "532591       1   -1.115385  -0.375000          -2.0         -1.0      -29.0   \n",
       "6920         1   -0.666667  -0.333333          -1.0         -1.0      -10.0   \n",
       "496017       1   -0.857143  -0.473684          -2.0         -1.0      -30.0   \n",
       "431512       1    0.181818   0.083333           1.0          1.0        2.0   \n",
       "169853       1    1.250000  -0.142857           2.0         -1.0        5.0   \n",
       "907080       1    1.571429   0.058824           2.0          1.0       11.0   \n",
       "324050       1    0.066667   0.000000           1.0          0.0        1.0   \n",
       "568210       1    0.545455   0.250000           1.0          1.0       12.0   \n",
       "207934       1    0.642857  -0.400000           1.5         -1.0       18.0   \n",
       "902517       1    0.333333   0.052632           1.0          1.0        4.0   \n",
       "361398       1    1.285714  -0.500000           2.0         -1.0        9.0   \n",
       "883237       1   -1.000000  -0.750000          -2.0         -1.0      -18.0   \n",
       "218606       1    1.047619   0.466667           2.0          1.0       22.0   \n",
       "529759       1   -1.000000   0.200000          -1.0          1.0       -3.0   \n",
       "947297       1    0.162791   0.000000           1.0          0.0        7.0   \n",
       "233868       1    0.600000  -0.066667           1.0         -1.0        9.0   \n",
       "506925       1   -0.500000   0.000000          -0.5          0.0       -1.0   \n",
       "884102       1    0.857143   0.120000           2.0          1.0       24.0   \n",
       "587768       1    0.333333  -0.120000           1.0         -1.0        8.0   \n",
       "989805       1   -0.480000  -0.200000           1.0         -1.0      -12.0   \n",
       "304347       1   -0.750000  -0.600000          -1.0         -1.0       -3.0   \n",
       "803024       1    1.600000   0.142857           2.0          1.0        8.0   \n",
       "766485       1    0.333333  -0.500000           0.5         -1.0        2.0   \n",
       "911210       1    1.052632   0.200000           2.0          1.0       20.0   \n",
       "...        ...         ...        ...           ...          ...        ...   \n",
       "248905       5    1.250000   0.200000           3.0          1.0       10.0   \n",
       "72122        5    1.750000   0.500000           2.0          1.0       14.0   \n",
       "549133       5    1.666667   1.000000           2.0          1.0        5.0   \n",
       "791652       5    1.133333   0.130435           2.0          1.0       17.0   \n",
       "485417       5    1.153846   0.310345           2.0          1.0       45.0   \n",
       "455091       5    0.777778  -0.037037           2.0         -1.0       14.0   \n",
       "268031       5    0.666667  -0.200000           2.0         -1.0        2.0   \n",
       "530998       5    3.500000   1.000000           3.5          1.0        7.0   \n",
       "346750       5    0.272727  -0.142857           0.0         -1.0        6.0   \n",
       "92748        5    1.166667   0.333333           1.5          1.0        7.0   \n",
       "63174        5    2.250000   0.666667           2.5          1.0        9.0   \n",
       "809832       5    2.000000  -1.000000           2.0         -1.0        2.0   \n",
       "80209        5    2.400000   0.500000           2.0          1.0       12.0   \n",
       "590541       5    1.304348   0.777778           2.0          1.0       30.0   \n",
       "930879       5    0.000000   0.333333           1.0          1.0        0.0   \n",
       "536222       5    1.125000   0.111111           1.5          1.0        9.0   \n",
       "527922       5    0.857143   0.250000           2.0          1.0       18.0   \n",
       "209239       5    2.000000  -0.333333           2.0         -1.0        2.0   \n",
       "470908       5    2.000000   1.000000           2.0          1.0        4.0   \n",
       "326468       5    1.666667   1.000000           2.0          1.0       10.0   \n",
       "653514       5    2.833333   1.000000           3.0          1.0       17.0   \n",
       "347435       5    1.578947   0.809524           2.0          1.0       30.0   \n",
       "508818       5   -3.000000  -0.600000          -3.0         -1.0       -3.0   \n",
       "636572       5    1.900000   0.555556           3.0          1.0       19.0   \n",
       "12184        5    2.200000   1.000000           2.0          1.0       22.0   \n",
       "727546       5   -2.000000  -0.384615          -2.0         -1.0      -12.0   \n",
       "773250       5    0.783784   0.151515           1.0          1.0       29.0   \n",
       "281119       5   -0.250000  -0.111111          -1.5         -1.0       -2.0   \n",
       "825828       5    1.760000   0.384615           2.0          1.0       44.0   \n",
       "797247       5    3.333333   0.600000           3.0          1.0       10.0   \n",
       "\n",
       "        bing_sum  word_count  pos_afinn_count  neg_afinn_count  \\\n",
       "31977        0.0          38              1.0              0.0   \n",
       "427067      -5.0          66              1.0              3.0   \n",
       "160033       3.0          76              4.0              0.0   \n",
       "751317      -1.0          47              2.0              2.0   \n",
       "43786        3.0          42              3.0              3.0   \n",
       "270377      -5.0         189              7.0              6.0   \n",
       "532591      -6.0         383              6.0             20.0   \n",
       "6920        -5.0          85              5.0             10.0   \n",
       "496017     -18.0         318             13.0             22.0   \n",
       "431512       2.0         282              6.0              5.0   \n",
       "169853      -1.0          78              3.0              1.0   \n",
       "907080       1.0         198              5.0              2.0   \n",
       "324050       0.0         184              9.0              6.0   \n",
       "568210       4.0         258             14.0              8.0   \n",
       "207934     -12.0         303             18.0             10.0   \n",
       "902517       1.0         343              7.0              5.0   \n",
       "361398      -6.0         272              6.0              1.0   \n",
       "883237     -12.0         177              4.0             14.0   \n",
       "218606       7.0         252             15.0              6.0   \n",
       "529759       1.0          41              1.0              2.0   \n",
       "947297       0.0         788             24.0             19.0   \n",
       "233868      -1.0         285             10.0              5.0   \n",
       "506925       0.0          32              1.0              1.0   \n",
       "884102       3.0         350             19.0              9.0   \n",
       "587768      -3.0         342             14.0             10.0   \n",
       "989805      -4.0         387             13.0             12.0   \n",
       "304347      -3.0          78              1.0              3.0   \n",
       "803024       1.0          84              4.0              1.0   \n",
       "766485      -4.0          71              3.0              3.0   \n",
       "911210       3.0         302             13.0              6.0   \n",
       "...          ...         ...              ...              ...   \n",
       "248905       2.0          68              6.0              2.0   \n",
       "72122        4.0          82              7.0              1.0   \n",
       "549133       3.0          39              3.0              0.0   \n",
       "791652       3.0         194             10.0              5.0   \n",
       "485417       9.0         304             29.0             10.0   \n",
       "455091      -1.0         298             12.0              6.0   \n",
       "268031      -1.0          43              2.0              1.0   \n",
       "530998       2.0          32              2.0              0.0   \n",
       "346750      -4.0         366             11.0             11.0   \n",
       "92748        2.0          51              5.0              1.0   \n",
       "63174        4.0          90              4.0              0.0   \n",
       "809832      -1.0          53              1.0              0.0   \n",
       "80209        4.0          60              5.0              0.0   \n",
       "590541      21.0         218             20.0              3.0   \n",
       "930879       2.0          49              3.0              2.0   \n",
       "536222       1.0          84              5.0              3.0   \n",
       "527922       4.0         228             15.0              6.0   \n",
       "209239      -2.0         188              1.0              0.0   \n",
       "470908       2.0          33              2.0              0.0   \n",
       "326468       2.0          50              5.0              1.0   \n",
       "653514       5.0          32              6.0              0.0   \n",
       "347435      17.0         269             15.0              4.0   \n",
       "508818      -3.0          48              0.0              1.0   \n",
       "636572       5.0          63              8.0              2.0   \n",
       "12184       16.0         192             10.0              0.0   \n",
       "727546      -5.0         239              0.0              6.0   \n",
       "773250       5.0         490             26.0             11.0   \n",
       "281119      -1.0          53              3.0              5.0   \n",
       "825828       5.0         234             23.0              2.0   \n",
       "797247       3.0          59              3.0              0.0   \n",
       "\n",
       "              ...         neg_bing_ratio  pos_afinn_density  pos_bing_density  \\\n",
       "31977         ...               1.000000           0.026316          0.026316   \n",
       "427067        ...               1.250000           0.015152          0.000000   \n",
       "160033        ...               0.000000           0.052632          0.039474   \n",
       "751317        ...               0.500000           0.042553          0.021277   \n",
       "43786         ...               0.166667           0.071429          0.095238   \n",
       "270377        ...               0.846154           0.037037          0.031746   \n",
       "532591        ...               0.423077           0.015666          0.013055   \n",
       "6920          ...               0.666667           0.058824          0.058824   \n",
       "496017        ...               0.800000           0.040881          0.031447   \n",
       "431512        ...               1.000000           0.021277          0.046099   \n",
       "169853        ...               1.000000           0.038462          0.038462   \n",
       "907080        ...               1.142857           0.025253          0.045455   \n",
       "324050        ...               0.666667           0.048913          0.054348   \n",
       "568210        ...               0.272727           0.054264          0.038760   \n",
       "207934        ...               0.750000           0.059406          0.029703   \n",
       "902517        ...               0.750000           0.020408          0.029155   \n",
       "361398        ...               1.285714           0.022059          0.011029   \n",
       "883237        ...               0.777778           0.022599          0.011299   \n",
       "218606        ...               0.190476           0.059524          0.043651   \n",
       "529759        ...               0.666667           0.024390          0.073171   \n",
       "947297        ...               0.674419           0.030457          0.036802   \n",
       "233868        ...               0.533333           0.035088          0.024561   \n",
       "506925        ...               0.500000           0.031250          0.031250   \n",
       "884102        ...               0.392857           0.054286          0.040000   \n",
       "587768        ...               0.583333           0.040936          0.032164   \n",
       "989805        ...               0.480000           0.033592          0.020672   \n",
       "304347        ...               1.000000           0.012821          0.012821   \n",
       "803024        ...               0.600000           0.047619          0.047619   \n",
       "766485        ...               1.000000           0.042254          0.028169   \n",
       "911210        ...               0.315789           0.043046          0.029801   \n",
       "...           ...                    ...                ...               ...   \n",
       "248905        ...               0.500000           0.088235          0.088235   \n",
       "72122         ...               0.250000           0.085366          0.073171   \n",
       "549133        ...               0.000000           0.076923          0.076923   \n",
       "791652        ...               0.666667           0.051546          0.067010   \n",
       "485417        ...               0.256410           0.095395          0.062500   \n",
       "455091        ...               0.777778           0.040268          0.043624   \n",
       "268031        ...               1.000000           0.046512          0.046512   \n",
       "530998        ...               0.000000           0.062500          0.062500   \n",
       "346750        ...               0.727273           0.030055          0.032787   \n",
       "92748         ...               0.333333           0.098039          0.078431   \n",
       "63174         ...               0.250000           0.044444          0.055556   \n",
       "809832        ...               1.000000           0.018868          0.000000   \n",
       "80209         ...               0.400000           0.083333          0.100000   \n",
       "590541        ...               0.130435           0.091743          0.110092   \n",
       "930879        ...               0.400000           0.061224          0.081633   \n",
       "536222        ...               0.500000           0.059524          0.059524   \n",
       "527922        ...               0.285714           0.065789          0.043860   \n",
       "209239        ...               4.000000           0.005319          0.010638   \n",
       "470908        ...               0.000000           0.060606          0.060606   \n",
       "326468        ...               0.000000           0.100000          0.040000   \n",
       "653514        ...               0.000000           0.187500          0.156250   \n",
       "347435        ...               0.105263           0.055762          0.070632   \n",
       "508818        ...               4.000000           0.000000          0.020833   \n",
       "636572        ...               0.200000           0.126984          0.111111   \n",
       "12184         ...               0.000000           0.052083          0.083333   \n",
       "727546        ...               1.500000           0.000000          0.016736   \n",
       "773250        ...               0.378378           0.053061          0.038776   \n",
       "281119        ...               0.625000           0.056604          0.075472   \n",
       "825828        ...               0.160000           0.098291          0.038462   \n",
       "797247        ...               0.333333           0.050847          0.067797   \n",
       "\n",
       "        neg_afinn_density  neg_bing_density  afinn_words_ratio  \\\n",
       "31977            0.000000          0.026316           0.105263   \n",
       "427067           0.045455          0.075758          -0.090909   \n",
       "160033           0.000000          0.000000           0.105263   \n",
       "751317           0.042553          0.042553          -0.063830   \n",
       "43786            0.071429          0.023810           0.023810   \n",
       "270377           0.031746          0.058201          -0.021164   \n",
       "532591           0.052219          0.028721          -0.075718   \n",
       "6920             0.117647          0.117647          -0.117647   \n",
       "496017           0.069182          0.088050          -0.094340   \n",
       "431512           0.017730          0.039007           0.007092   \n",
       "169853           0.012821          0.051282           0.064103   \n",
       "907080           0.010101          0.040404           0.055556   \n",
       "324050           0.032609          0.054348           0.005435   \n",
       "568210           0.031008          0.023256           0.046512   \n",
       "207934           0.033003          0.069307           0.059406   \n",
       "902517           0.014577          0.026239           0.011662   \n",
       "361398           0.003676          0.033088           0.033088   \n",
       "883237           0.079096          0.079096          -0.101695   \n",
       "218606           0.023810          0.015873           0.087302   \n",
       "529759           0.048780          0.048780          -0.073171   \n",
       "947297           0.024112          0.036802           0.008883   \n",
       "233868           0.017544          0.028070           0.031579   \n",
       "506925           0.031250          0.031250          -0.031250   \n",
       "884102           0.025714          0.031429           0.068571   \n",
       "587768           0.029240          0.040936           0.023392   \n",
       "989805           0.031008          0.031008          -0.031008   \n",
       "304347           0.038462          0.051282          -0.038462   \n",
       "803024           0.011905          0.035714           0.095238   \n",
       "766485           0.042254          0.084507           0.028169   \n",
       "911210           0.019868          0.019868           0.066225   \n",
       "...                   ...               ...                ...   \n",
       "248905           0.029412          0.058824           0.147059   \n",
       "72122            0.012195          0.024390           0.170732   \n",
       "549133           0.000000          0.000000           0.128205   \n",
       "791652           0.025773          0.051546           0.087629   \n",
       "485417           0.032895          0.032895           0.148026   \n",
       "455091           0.020134          0.046980           0.046980   \n",
       "268031           0.023256          0.069767           0.046512   \n",
       "530998           0.000000          0.000000           0.218750   \n",
       "346750           0.030055          0.043716           0.016393   \n",
       "92748            0.019608          0.039216           0.137255   \n",
       "63174            0.000000          0.011111           0.100000   \n",
       "809832           0.000000          0.018868           0.037736   \n",
       "80209            0.000000          0.033333           0.200000   \n",
       "590541           0.013761          0.013761           0.137615   \n",
       "930879           0.040816          0.040816           0.000000   \n",
       "536222           0.035714          0.047619           0.107143   \n",
       "527922           0.026316          0.026316           0.078947   \n",
       "209239           0.000000          0.021277           0.010638   \n",
       "470908           0.000000          0.000000           0.121212   \n",
       "326468           0.020000          0.000000           0.200000   \n",
       "653514           0.000000          0.000000           0.531250   \n",
       "347435           0.014870          0.007435           0.111524   \n",
       "508818           0.020833          0.083333          -0.062500   \n",
       "636572           0.031746          0.031746           0.301587   \n",
       "12184            0.000000          0.000000           0.114583   \n",
       "727546           0.025105          0.037657          -0.050209   \n",
       "773250           0.022449          0.028571           0.059184   \n",
       "281119           0.094340          0.094340          -0.037736   \n",
       "825828           0.008547          0.017094           0.188034   \n",
       "797247           0.000000          0.016949           0.169492   \n",
       "\n",
       "        bing_words_ratio  cap_words_count  exclamation_count  all_caps_density  \n",
       "31977           0.000000                0                  0          0.000000  \n",
       "427067         -0.075758                5                  0          0.075758  \n",
       "160033          0.039474                0                  0          0.000000  \n",
       "751317         -0.021277                4                  0          0.085106  \n",
       "43786           0.071429                0                  0          0.000000  \n",
       "270377         -0.026455                0                  0          0.000000  \n",
       "532591         -0.015666                1                  2          0.002611  \n",
       "6920           -0.058824                0                  0          0.000000  \n",
       "496017         -0.056604                0                  5          0.000000  \n",
       "431512          0.007092                3                  0          0.010638  \n",
       "169853         -0.012821                1                  0          0.012821  \n",
       "907080          0.005051                6                  1          0.030303  \n",
       "324050          0.000000                2                  0          0.010870  \n",
       "568210          0.015504                0                  0          0.000000  \n",
       "207934         -0.039604                3                  7          0.009901  \n",
       "902517          0.002915                0                  1          0.000000  \n",
       "361398         -0.022059                2                  1          0.007353  \n",
       "883237         -0.067797                0                  0          0.000000  \n",
       "218606          0.027778                1                  0          0.003968  \n",
       "529759          0.024390                2                  1          0.048780  \n",
       "947297          0.000000                0                  0          0.000000  \n",
       "233868         -0.003509                0                  0          0.000000  \n",
       "506925          0.000000                0                  0          0.000000  \n",
       "884102          0.008571                4                  0          0.011429  \n",
       "587768         -0.008772                2                  2          0.005848  \n",
       "989805         -0.010336                2                  2          0.005168  \n",
       "304347         -0.038462                1                  1          0.012821  \n",
       "803024          0.011905                0                  0          0.000000  \n",
       "766485         -0.056338                0                  0          0.000000  \n",
       "911210          0.009934                2                  0          0.006623  \n",
       "...                  ...              ...                ...               ...  \n",
       "248905          0.029412                1                  2          0.014706  \n",
       "72122           0.048780                0                  0          0.000000  \n",
       "549133          0.076923                0                  0          0.000000  \n",
       "791652          0.015464                6                  3          0.030928  \n",
       "485417          0.029605                1                  0          0.003289  \n",
       "455091         -0.003356                0                  0          0.000000  \n",
       "268031         -0.023256                0                  0          0.000000  \n",
       "530998          0.062500                0                  0          0.000000  \n",
       "346750         -0.010929                0                  4          0.000000  \n",
       "92748           0.039216                3                  0          0.058824  \n",
       "63174           0.044444                0                  0          0.000000  \n",
       "809832         -0.018868                0                  0          0.000000  \n",
       "80209           0.066667                0                  0          0.000000  \n",
       "590541          0.096330                0                  6          0.000000  \n",
       "930879          0.040816                0                  0          0.000000  \n",
       "536222          0.011905                0                  3          0.000000  \n",
       "527922          0.017544                0                  0          0.000000  \n",
       "209239         -0.010638                0                  4          0.000000  \n",
       "470908          0.060606                0                  1          0.000000  \n",
       "326468          0.040000                0                  1          0.000000  \n",
       "653514          0.156250                1                  0          0.031250  \n",
       "347435          0.063197                0                  0          0.000000  \n",
       "508818         -0.062500                0                  0          0.000000  \n",
       "636572          0.079365                0                  0          0.000000  \n",
       "12184           0.083333                1                  0          0.005208  \n",
       "727546         -0.020921                0                  2          0.000000  \n",
       "773250          0.010204                0                  0          0.000000  \n",
       "281119         -0.018868                0                  1          0.000000  \n",
       "825828          0.021368                0                  1          0.000000  \n",
       "797247          0.050847                0                  0          0.000000  \n",
       "\n",
       "[150000 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try downsampling so each group is represented equally\n",
    "\n",
    "r1 = review_stats[review_stats['rating']==1].sample(30000)\n",
    "r2 = review_stats[review_stats['rating']==2].sample(30000)\n",
    "r3 = review_stats[review_stats['rating']==3].sample(30000)\n",
    "r4 = review_stats[review_stats['rating']==4].sample(30000)\n",
    "r5 = review_stats[review_stats['rating']==5].sample(30000)\n",
    "\n",
    "review_stats_downsampled = pd.concat([r1,r2,r3,r4,r5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = review_stats_downsampled['rating'].values\n",
    "X = review_stats_downsampled.drop('rating', axis=1).values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Try the MinMaxScaler to see if we'd get a different result\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "steps = [('minmax', MinMaxScaler()),\n",
    "         ('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "rf_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262466666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.40      0.35      6068\n",
      "          2       0.22      0.23      0.23      6031\n",
      "          3       0.23      0.21      0.22      6071\n",
      "          4       0.23      0.20      0.21      5912\n",
      "          5       0.31      0.26      0.28      5918\n",
      "\n",
      "avg / total       0.26      0.26      0.26     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.78      0.71     18170\n",
      "          1       0.53      0.37      0.44     11830\n",
      "\n",
      "avg / total       0.61      0.62      0.60     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_stats_downsampled['pos_review'] = 0\n",
    "review_stats_downsampled.loc[review_stats['rating'] >= 4,'pos_review'] = 1\n",
    "\n",
    "y_pos = review_stats_downsampled['pos_review'].values\n",
    "X_pos = review_stats_downsampled.drop(['rating', 'pos_review'], axis=1).values\n",
    "\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(\n",
    "    X_pos, y_pos, test_size=0.2, random_state=1)\n",
    "\n",
    "rf.fit(X_train_pos, y_train_pos)\n",
    "rf_y_new_pred = rf.predict(X_test_pos)\n",
    "print(classification_report(y_test_pos, rf_y_new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62050000000000005"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test_pos, y_test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb057e5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_prob = rf.predict_proba(X_test_pos)[:,1]\n",
    "# we unpack the result into three variables: False Postiive Rate\n",
    "# True Positive Rate, and Thresholds (the values of p)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_pos, y_pred_prob)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66108355307\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.22      0.31     62182\n",
      "          1       0.68      0.90      0.78    113407\n",
      "\n",
      "avg / total       0.63      0.66      0.61    175589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# what about 2 variable classification? How does that work with MLP\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), activation='logistic', alpha=0.0008883, learning_rate='invscaling', \n",
    "                   tol=0.000583)\n",
    "\n",
    "mlp.fit(X_train_pos, y_train_pos)\n",
    "mlp_y_new_pred = mlp.predict(X_test_pos)\n",
    "print(mlp.score(X_test_pos, y_test_pos))\n",
    "print(classification_report(y_test_pos, mlp_y_new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb033c36d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_prob_mlp = rf.predict_proba(X_test_pos)[:,1]\n",
    "# we unpack the result into three variables: False Postiive Rate\n",
    "# True Positive Rate, and Thresholds (the values of p)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_pos, y_pred_prob_mlp)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (MLP)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
