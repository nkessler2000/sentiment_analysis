{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "\n",
    "# import modules and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "my_dir = os.path.realpath('.')\n",
    "db_file = os.path.join(my_dir, '../../gr_sentiment_analysis/data/books.db')\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "review_stats = pd.read_sql_query('SELECT * FROM review_stats',con=conn)\n",
    "\n",
    "# Clean up the data a bit. Remove reviews with a score of 0 since they won't be part of the prediction model \n",
    "\n",
    "review_stats = review_stats[review_stats['rating'] != 0]\n",
    "\n",
    "# Review ID is not needed for this analysis so should be dropped\n",
    "if review_stats.columns.contains('review_id'):\n",
    "    review_stats.drop('review_id', axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "# remove any reviews with a total AFINN or Bing count of 0, since this means there are no matching\n",
    "# words in either lexicon and these reviews cannot be used in this analysis\n",
    "review_stats = review_stats[(review_stats.total_afinn_count != 0) & (review_stats.total_bing_count != 0)]\n",
    "# this leaves 918438 total reviews\n",
    "\n",
    "# remove outliers where the Z-score of the pos or neg word counts is < 3\n",
    "review_stats = review_stats[(\n",
    "    np.abs(stats.zscore(review_stats[['pos_afinn_count', 'neg_afinn_count', 'pos_bing_count', 'neg_bing_count']])) < 3\n",
    ").all(axis=1)]\n",
    "\n",
    "# with all outliers removed (having a count +/- 3 SDs), 889807 rows remain. \n",
    "\n",
    "# Rating is our target variable, the other columns are features. \n",
    "y = review_stats['rating'].values\n",
    "X = review_stats.drop('rating', axis=1).values\n",
    "\n",
    "# Create a training and testing set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27819109  0.28076061  0.2828822   0.27487076  0.27645694]\n"
     ]
    }
   ],
   "source": [
    "# Let's try a random search using decision trees and see if we get a better result\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create our pipeline and parameter dict\n",
    "# tree_steps = [('scaler', StandardScaler()),\n",
    "#              ('tree', DecisionTreeClassifier())] \n",
    "\n",
    "\n",
    "nb_cv = cross_val_score(GaussianNB(), X, y, cv=5, n_jobs=2)\n",
    "print(nb_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.09      0.39      0.15      6664\n",
      "          2       0.12      0.23      0.16     15953\n",
      "          3       0.26      0.21      0.23     40160\n",
      "          4       0.37      0.48      0.42     62340\n",
      "          5       0.54      0.09      0.16     52845\n",
      "\n",
      "avg / total       0.36      0.28      0.27    177962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
